# PostgreSQL HA with Patroni
TODO

## Backups
High availability is not disaster recovery. Patroni will do its best to keep
your cluster online, but cannot help you if bugs or malware eat your data.
Therefore, proper database backups are highly recommended.

container-ops can deploy [Barman](https://pgbarman.org/) to do this for you.
In addition to scheduled physical (pg_basebackup) backups, it uses WAL
streaming to allow point-in-time recovery with accuracy of *minutes*.

### Deploying Barman
Barman runs its WAL archiving and scheduled full backups as a separate Podman
pod/container. You can deploy it on any machine; like the database instances,
all traffic will be handled using Nebula overlay.

A single instance of Barman can backup multiple Patroni clusters, as long as
all of them are in same Nebula network. Deploying multiple instances of Barman
within same machine is not supported.

So, let's deploy it:
```python
# Deploying local proxy for PostgreSQL access is recommended for HA
# This applies to Barman just like any other PostgreSQL client
# (but the proxy can of course be shared with other clients)
patroni.proxy(
    cluster=YOUR_CLUSTER,
    hostname=f'{host.name}.pgproxy.your-domain.internal',
)

# Unless they already exist, remember Postgres passwords!
podman.secret('superuser-secret', source='secrets/postgres.json', json_key='pg_superuser')
podman.secret('replication-secret', source='secrets/postgres.json', json_key='pg_replication')

# And finally, deploy scheduled backups
patroni.barman_backups(
    sources=[
        patroni.BackupSource(
            cluster=YOUR_CLUSTER,
            pgproxy_hostname=f'{host.name}.pgproxy.your-domain.internal',
            superuser_secret='superuser-secret',
            replication_secret='replication-secret',
        )
    ],
    hostname='barman.containerops.test',
)
```

TODO explain how to review barman logs

### Exporting snapshots
To get restorable data out of Barman, run this on the machine you deployed it on:

```python
patroni.restore_backup(
    cluster_id=YOUR_CLUSTER.cluster_id,
    restore_name='whatever-unique-name',
)
```

The restorable PostgreSQL data directory will be available at
`/var/containerops/data/barman_restored/whatever-unique-name`.

### Restoring
Barman exports **cannot** be restored on existing Patroni clusters. You'll
need to create a new cluster. It is highly recommended that you do this with
new `cluster_id` and hostnames - otherwise, it rather difficult to *test*
your backups without harming the source cluster.

Once you have decided where to run the new cluster, copy the export somewhere
on that machine. It can be any machine that is *not* going to be a read replica.

Finally, create the cluster as usual, with one little addition:
```python
CLUSTER_CONFIG = patroni.ClusterConfig(
    # ... rest of options
    restore_from_backup='/path/to/your/restore'
)

patroni.instance(...) # ... and so on, exactly as before
```

Finally, if you so wish, you can change your proxies to refer to the new
cluster's configuration. This will shift traffic from the old cluster to the
new one.

#### Restoring to non-Patroni PostgreSQL?
This is a bit more tricky. The data is all there, but the PostgreSQL
configuration generated by Patroni is very Patroni-specific. In future,
container-ops might do this for you.